{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5686853f-4655-4e79-af04-fe24aac1756e",
   "metadata": {},
   "source": [
    "## ESAT K Estimation Workflow 2 - Bootstrap Evaluation\n",
    "\n",
    "This notebook implements a bootstrap approach to using solution profile variabilty to estimate optimal number of factors in a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206ac55f-9259-4ce1-b87e-3302d2ed00f9",
   "metadata": {},
   "source": [
    "#### Code Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9de6b9e-89a5-4db8-94d4-2226605d9ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from esat.data.datahandler import DataHandler\n",
    "from esat.model.sa import SA\n",
    "from esat.model.batch_sa import BatchSA\n",
    "from esat.data.analysis import ModelAnalysis, BatchAnalysis\n",
    "from esat.error.bootstrap import Bootstrap\n",
    "from esat_eval.simulator import Simulator\n",
    "from esat.estimator import FactorEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47e80dbc-702b-4fca-b800-0660033a251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synethic dataset parameter value ranges\n",
    "syn_factors_min = 3\n",
    "syn_factors_max = 8\n",
    "\n",
    "syn_features_min = 15\n",
    "syn_features_max = 45\n",
    "\n",
    "syn_samples_min = 200\n",
    "syn_samples_max = 1000\n",
    "\n",
    "outliers = True\n",
    "outliers_p_min = 0.05\n",
    "outliers_p_max = 0.1\n",
    "outliers_mag_min = 1.1\n",
    "outliers_mag_max = 2\n",
    "\n",
    "noise_mean_min = 0.05\n",
    "noise_mean_max = 0.15\n",
    "noise_scale = 0.01\n",
    "\n",
    "uncertainty_mean_min = 0.05\n",
    "uncertainty_mean_max = 0.15\n",
    "uncertainty_scale = 0.01\n",
    "\n",
    "contr_curve_min_range = [0.0, 1.0]\n",
    "contr_curve_max_range = [2.0, 5.0]\n",
    "contr_curve_scale_range = [0.1, 0.5]\n",
    "\n",
    "random_seed = 337\n",
    "k_coef = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2408991-45a6-4a5c-ac14-388f79cbab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e045f7a-8a9a-4316-b60e-018935328241",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "372a6a6a-612a-4d00-a3ae-be12aecb0e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the simulator with the above parameters\n",
    "def generate_synthetic_data(true_factor):\n",
    "    n_features = rng.integers(low=syn_features_min, high=syn_features_max, size=1)[0]\n",
    "    n_samples = rng.integers(low=syn_samples_min, high=syn_samples_max, size=1)[0]\n",
    "    i_outlier_p = round(rng.uniform(low=outliers_p_min, high=outliers_p_max, size=1)[0], 2)\n",
    "    i_outlier_mag = round(rng.uniform(low=outliers_mag_min, high=outliers_mag_max, size=1)[0], 2)\n",
    "    contribution_max = round(rng.uniform(low=1.0, high=10.0, size=1)[0], 2)\n",
    "    print(f\"True Factors: {true_factor}, Features: {n_features}, Samples: {n_samples}, Outliers %: {i_outlier_p}, Outliers Magnitude: {i_outlier_mag}, Contribution Max: {contribution_max}\")\n",
    "    simulator = Simulator(seed=rng.integers(low=0, high=10, size=1)[0],\n",
    "                          factors_n=true_factor,\n",
    "                          features_n=n_features,\n",
    "                          samples_n=n_samples,\n",
    "                          outliers=outliers,\n",
    "                          outlier_p=i_outlier_p,\n",
    "                          outlier_mag=i_outlier_mag,\n",
    "                          contribution_max=contribution_max,\n",
    "                          noise_mean_min=noise_mean_min,\n",
    "                          noise_mean_max=noise_mean_max,\n",
    "                          noise_scale=noise_scale,\n",
    "                          uncertainty_mean_min=uncertainty_mean_min,\n",
    "                          uncertainty_mean_max=uncertainty_mean_max,\n",
    "                          uncertainty_scale=uncertainty_scale,\n",
    "                          verbose=False\n",
    "                         )\n",
    "    curved_factors_count = rng.integers(low=0, high=true_factor, size=1)[0]\n",
    "    curved_factor_list = rng.choice(list(range(true_factor)), size=curved_factors_count, replace=False)\n",
    "    for c_i in curved_factor_list:\n",
    "        # parameters not used by the curve type are ignored\n",
    "        i_curve_type = rng.choice(['uniform', 'decreasing', 'increasing', 'logistic', 'periodic'], size=1)[0]\n",
    "        i_curve_min = rng.uniform(low=contr_curve_min_range[0], high=contr_curve_min_range[1], size=1)[0]\n",
    "        i_curve_max = rng.uniform(low=contr_curve_max_range[0], high=contr_curve_max_range[1], size=1)[0]\n",
    "        i_curve_scale = rng.uniform(low=contr_curve_scale_range[0], high=contr_curve_scale_range[1], size=1)[0]\n",
    "        i_curve_frequency = rng.uniform(low=0.1, high=0.9, size=1)[0]\n",
    "        \n",
    "        # To keep all as uniform comment out the line below\n",
    "        # simulator.update_contribution(factor_i=c_i, curve_type=i_curve_type, scale=i_curve_scale, frequency=i_curve_frequency, minimum=i_curve_min, maximum=i_curve_max)\n",
    "    \n",
    "    syn_input_df, syn_uncertainty_df = simulator.get_data()\n",
    "    data_handler = DataHandler.load_dataframe(input_df=syn_input_df, uncertainty_df=syn_uncertainty_df)\n",
    "    data_handler.metrics\n",
    "    V, U = data_handler.get_data()\n",
    "    return V, U\n",
    "\n",
    "\n",
    "def run_bs(k, bV, bU, bseed, bs_instances: int = 20, block_size: int = 4, threshold: float = 0.9):\n",
    "    # Runs a bootstrap instance\n",
    "    # Steps:\n",
    "    # 1. Generate base model with a specified number of factors\n",
    "    # 2. Generate bs_instances number of bootstrap datasets\n",
    "    # 3. For each bootstrap dataset, use the base model H profiles for initialization. Run to convergence.\n",
    "    # 4. On each converged bs model, calculate the average correlation of the mapped profiles.\n",
    "    # 5. Reported metrics for each bootstrap run. K, % mapped profiles, mean mapped correlation, mean overall correlation, mean QTrue\n",
    "\n",
    "    # Base Model, step 1\n",
    "    base_sa = SA(V=bV, U=bU, factors=k, seed=bseed, verbose=False)\n",
    "    base_sa.initialize()\n",
    "    base_sa.train(max_iter=20000, converge_delta=0.1, converge_n=10)\n",
    "\n",
    "    # BS instance, steps 2-3\n",
    "    bs = Bootstrap(sa=base_sa, model_selected=-1, bootstrap_n=bs_instances, block_size=block_size, threshold=threshold, seed=bseed, parallel=True)\n",
    "    bs.run()\n",
    "\n",
    "    # Evaluate correlations, step 4\n",
    "    # for each bs result get the mapping correlations bs.bs_results[1]['mapping']\n",
    "    compare_count = 0\n",
    "    mapped = 0\n",
    "    mapped_correlations = []\n",
    "    notmapped_correlations = []\n",
    "    for i, i_result in bs.bs_results.items():\n",
    "        i_mapping = i_result[\"mapping\"]\n",
    "        for j, j_factor in i_mapping.items():\n",
    "            compare_count += 1\n",
    "            if j_factor[\"mapped\"]:\n",
    "                mapped_correlations.append(j_factor[\"r2\"])\n",
    "                mapped += 1\n",
    "            else:\n",
    "                notmapped_correlations.append(j_factor[\"r2\"])\n",
    "    # return results, step 5\n",
    "    mapped_correlations_mean = 0.0 if len(mapped_correlations) == 0 else round(np.mean(mapped_correlations), 4)\n",
    "    bs_results = {\n",
    "        \"k\": k,\n",
    "        \"seed\": bseed,\n",
    "        \"% mapped\": round((mapped/compare_count) * 100, 2),\n",
    "        \"mean mapped r2\":mapped_correlations_mean,\n",
    "        \"mean r2\": round((np.sum(mapped_correlations)+np.sum(notmapped_correlations))/(len(mapped_correlations)+len(notmapped_correlations)), 4),\n",
    "        \"mean QRobust\": round(np.mean(bs.q_results), 4)\n",
    "    }\n",
    "    return bs_results\n",
    "\n",
    "def run_bs_batch(k, n_batches, bV, bU, bseed, bs_instances: int = 20, block_size: int = 4, threshold: float = 0.9, ):\n",
    "    results = {\n",
    "        \"k\": k,\n",
    "        \"seed\": bseed,\n",
    "        \"% mapped\": [],\n",
    "        \"mean mapped r2\": [],\n",
    "        \"mean r2\": [],\n",
    "        \"mean QRobust\": []\n",
    "    }\n",
    "    for i in range(n_batches):\n",
    "        i_seed = rng.integers(low=0, high=1e10, endpoint=True, size=1)[0]\n",
    "        i_result = run_bs(k=i_factor, bV=bV, bU=bU, bseed=i_seed, bs_instances=bs_instances)\n",
    "        results[\"% mapped\"].append(i_result[\"% mapped\"])\n",
    "        results[\"mean mapped r2\"].append(i_result[\"mean mapped r2\"])\n",
    "        results[\"mean r2\"].append(i_result[\"mean r2\"])\n",
    "        results[\"mean QRobust\"].append(i_result[\"mean QRobust\"])\n",
    "    results[\"% mapped\"] = round(np.mean(results[\"% mapped\"]), 4)\n",
    "    results[\"mean mapped r2\"] = round(np.mean(results[\"mean mapped r2\"]), 4) if len(results[\"mean mapped r2\"]) > 0 else 0.0\n",
    "    results[\"mean r2\"] = round(np.mean(results[\"mean r2\"]), 4)\n",
    "    results[\"mean QRobust\"] = round(np.mean(results[\"mean QRobust\"]), 4)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf75aee-32ec-49d5-afc9-2dc5760ede24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Factors: 9, Features: 18, Samples: 923, Outliers %: 0.07, Outliers Magnitude: 1.14, Contribution Max: 1.88\n",
      "Results: {'k': 2, 'seed': 6989272562, '% mapped': 93.6667, 'mean mapped r2': 0.0, 'mean r2': 0.9776, 'mean QRobust': 123929.6937}, Runtime 68.89 sec(s)\n",
      "Results: {'k': 3, 'seed': 3044908328, '% mapped': 65.5567, 'mean mapped r2': 0.0, 'mean r2': 0.9085, 'mean QRobust': 84988.5116}, Runtime 94.12 sec(s)\n",
      "Results: {'k': 4, 'seed': 13208742, '% mapped': 72.3333, 'mean mapped r2': 0.0, 'mean r2': 0.9174, 'mean QRobust': 57114.4775}, Runtime 147.95 sec(s)\n",
      "Results: {'k': 5, 'seed': 6455208392, '% mapped': 65.6, 'mean mapped r2': 0.0, 'mean r2': 0.8888, 'mean QRobust': 41327.8813}, Runtime 268.92 sec(s)\n",
      "Results: {'k': 6, 'seed': 1880114858, '% mapped': 70.3333, 'mean mapped r2': 0.0, 'mean r2': 0.9121, 'mean QRobust': 27968.5813}, Runtime 269.63 sec(s)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "true_k = 9\n",
    "i_V, i_U = generate_synthetic_data(true_factor=true_k)\n",
    "\n",
    "n_batches = 3\n",
    "bs_instances = 50\n",
    "min_factors = 2\n",
    "max_factors = 10\n",
    "\n",
    "results_list0 = []\n",
    "for i_factor in range(min_factors, max_factors+1):\n",
    "    t0 = time.time()\n",
    "    bseed = rng.integers(low=0, high=1e10, endpoint=True, size=1)[0]\n",
    "    i_results = run_bs_batch(k=i_factor, n_batches=n_batches, bV=i_V, bU=i_U, bseed=bseed, bs_instances=bs_instances)\n",
    "    results_list0.append(i_results)\n",
    "    t1 = time.time()\n",
    "    print(f\"Results: {i_results}, Runtime {round(t1-t0, 2)} sec(s)\")\n",
    "# results_list0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2779d2e-8365-4ae1-8af6-95b4e947752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_labels = [f\"Factor {i}\" for i in range(min_factors, max_factors+1)]\n",
    "q_robust = []\n",
    "mean_mapped_r2 = []\n",
    "mean_r2 = []\n",
    "mapped_p = []\n",
    "\n",
    "best_r2_i = -1\n",
    "best_r2 = 0\n",
    "best_mr2_i = -1\n",
    "best_mr2 = 0\n",
    "\n",
    "for i, i_r in enumerate(results_list0):\n",
    "    mr2 = i_r[\"mean mapped r2\"]\n",
    "    r2 = i_r[\"mean r2\"]\n",
    "    if best_r2 < r2:\n",
    "        best_r2 = r2\n",
    "        best_r2_i = i + min_factors\n",
    "    if best_mr2 < mr2:\n",
    "        best_mr2 = mr2\n",
    "        best_mr2_i = i + min_factors\n",
    "    q_robust.append(i_r[\"mean QRobust\"])\n",
    "    mean_mapped_r2.append(mr2)\n",
    "    mean_r2.append(r2)\n",
    "    mapped_p.append(i_r[\"% mapped\"])\n",
    "\n",
    "print(f\"True K: {true_k}, Best Mapped R2: factor={best_mr2_i}, R2={best_mr2}, Best R2: factor={best_r2_i}, R2={best_r2}\")\n",
    "\n",
    "results_fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "results_fig.add_trace(go.Scatter(name=\"QRobust\", x=factor_labels, y=q_robust, mode=\"lines\"), secondary_y=True)\n",
    "results_fig.add_trace(go.Bar(name=\"Mean Mapped R2\", x=factor_labels, y=mean_mapped_r2), secondary_y=False)\n",
    "results_fig.add_trace(go.Bar(name=\"Mean R2\", x=factor_labels, y=mean_r2), secondary_y=False)\n",
    "\n",
    "results_fig.update_layout(barmode='group', width=1200, height=800, title_text=\"Bootstrap K Estimate\", hovermode='x unified')\n",
    "results_fig.update_yaxes(title=\"Q(Robust)\", secondary_y=True)\n",
    "results_fig.update_yaxes(title=\"R2\", secondary_y=False)\n",
    "results_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9eeaf0-b609-4ac8-8a4d-e899e53c0cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_scores = []\n",
    "bs_r_scores = []\n",
    "for i, i_r in enumerate(results_list0):\n",
    "    mr2 = i_r[\"mean mapped r2\"]\n",
    "    r2 = i_r[\"mean r2\"]\n",
    "    p_m = i_r[\"% mapped\"]\n",
    "    bs_scores.append(p_m * mr2)\n",
    "    bs_r_scores.append(p_m * r2)\n",
    "bs_df = pd.DataFrame(data={\"BS Score\": bs_scores, \"All Score\": bs_r_scores, \"Factors\": factor_labels})\n",
    "print(f\"Estimated K - True K: {true_k}, Mapped Score: {bs_df.iloc[bs_df['BS Score'].idxmax()]['Factors']}, R2 Score: {bs_df.iloc[bs_df['All Score'].idxmax()]['Factors']}\")\n",
    "bs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ee36d66-7066-44d1-ae0b-b8b3e2413bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 998 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Sampling parameters\n",
    "n_batches = 5\n",
    "bs_instances = 10\n",
    "min_factors = 2\n",
    "max_factors = 10\n",
    "all_results = []\n",
    "\n",
    "# for j in range(100):\n",
    "#     t0 = time.time()\n",
    "#     true_k = rng.integers(low=syn_factors_min, high=syn_factors_max, endpoint=True, size=1)[0]\n",
    "#     i_V, i_U = generate_synthetic_data(true_factor=true_k)\n",
    "    \n",
    "#     results_list = []\n",
    "#     predicted_k = -1\n",
    "#     best_r2 = 0\n",
    "#     for i_factor in range(min_factors, max_factors+1):\n",
    "#         bseed = rng.integers(low=0, high=1e10, endpoint=True, size=1)[0]\n",
    "#         i_results = run_bs_batch(k=i_factor, n_batches=n_batches, bV=i_V, bU=i_U, bseed=bseed, bs_instances=bs_instances)\n",
    "#         if i_results['mean r2'] > best_r2:\n",
    "#             best_r2 = i_results['mean r2']\n",
    "#             predicted_k = i_results['k']\n",
    "#         results_list.append(i_results)\n",
    "#     t1 = time.time()\n",
    "#     print(f\"Predicted K: {predicted_k}, R2: {best_r2}. Runtime: {round(t1-t0, 4)} sec\")\n",
    "#     all_results.append(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1628b9e7-70ec-4ae2-9ee5-98e05e1f72de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b8c85-86b3-4957-a694-ed0681e55011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
