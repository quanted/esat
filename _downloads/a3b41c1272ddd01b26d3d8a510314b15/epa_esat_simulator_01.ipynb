{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5686853f-4655-4e79-af04-fe24aac1756e",
   "metadata": {},
   "source": [
    "## Environmental Source Apportionment Toolkit (ESAT) Simulator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec139f-6a92-417b-9b19-b58409d85e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When running from Google Colab or other Jupyter notebook cloud environment, the esat python package may need to be installed.\n",
    "# If the python package file is available locally run a pip install for the specific wheel for your current OS/Arch\n",
    "#! pip install esat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206ac55f-9259-4ce1-b87e-3302d2ed00f9",
   "metadata": {},
   "source": [
    "#### Code Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de6b9e-89a5-4db8-94d4-2226605d9ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esat.data.datahandler import DataHandler\n",
    "from esat.model.batch_sa import BatchSA\n",
    "from esat.data.analysis import ModelAnalysis, BatchAnalysis\n",
    "from esat_eval.simulator import Simulator\n",
    "from esat.estimator import FactorEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfb2b9c-98ee-4482-a0f9-c06b1eeb651f",
   "metadata": {},
   "source": [
    "#### Synthetic Dataset\n",
    "\n",
    "Generate a synthetic dataset where the factor profiles and contributions are pre-determined for model output analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ed6eb-46b4-4d3d-8085-19009c083e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synethic dataset parameters\n",
    "seed = 42\n",
    "syn_factors = 6                # Number of factors in the synthetic dataset\n",
    "syn_features = 40              # Number of features in the synthetic dataset\n",
    "syn_samples = 5000             # Number of samples in the synthetic dataset\n",
    "outliers = True                # Add outliers to the dataset\n",
    "outlier_p = 0.10               # Decimal percent of outliers in the dataset\n",
    "outlier_mag = 1.25                # Magnitude of outliers\n",
    "contribution_max = 2           # Maximum value of the contribution matrix (W) (Randomly sampled from a uniform distribution)\n",
    "noise_mean_min = 0.03          # Min value for the mean of noise added to the synthetic dataset, used to randomly determine the mean decimal percentage of the noise for each feature.\n",
    "noise_mean_max = 0.05          # Max value for the mean of noise added to the synthetic dataset, used to randomly determine the mean decimal percentage of the noise for each feature.\n",
    "noise_scale = 0.02             # Scale of the noise added to the synthetic dataset\n",
    "uncertainty_mean_min = 0.04    # Min value for the mean uncertainty of a data feature, used to randomly determine the mean decimal percentage for each feature in the uncertainty dataset. \n",
    "uncertainty_mean_max = 0.06    # Max value for the mean uncertainty of a data feature, used to randomly determine the mean decimal percentage for each feature in the uncertainty dataset. \n",
    "uncertainty_scale = 0.01       # Scale of the uncertainty matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd06d50-6afb-4cdf-a20c-3a487b8a7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the simulator with the above parameters\n",
    "simulator = Simulator(seed=seed,\n",
    "                      factors_n=syn_factors,\n",
    "                      features_n=syn_features,\n",
    "                      samples_n=syn_samples,\n",
    "                      outliers=outliers,\n",
    "                      outlier_p=outlier_p,\n",
    "                      outlier_mag=outlier_mag,\n",
    "                      contribution_max=contribution_max,\n",
    "                      noise_mean_min=noise_mean_min,\n",
    "                      noise_mean_max=noise_mean_max,\n",
    "                      noise_scale=noise_scale,\n",
    "                      uncertainty_mean_min=uncertainty_mean_min,\n",
    "                      uncertainty_mean_max=uncertainty_mean_max,\n",
    "                      uncertainty_scale=uncertainty_scale\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bb55be-07a1-44a3-98a0-d91855b9d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example command for passing in a custom factor profile matrix, instead of the randomly generated profile matrix.\n",
    "# my_profile = np.ones(shape=(syn_factors, syn_features))\n",
    "# simulator.generate_profiles(profiles=my_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5983ad-0d02-4938-9943-31bf0f889414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to customize the factor contributions. Curve_type options: 'uniform', 'decreasing', 'increasing', 'logistic', 'periodic'\n",
    "# simulator.update_contribution(factor_i=0, curve_type=\"logistic\", scale=0.1, frequency=0.5)\n",
    "# simulator.update_contribution(factor_i=1, curve_type=\"periodic\", minimum=0.0, maximum=1.0, frequency=0.5, scale=0.1)\n",
    "# simulator.update_contribution(factor_i=2, curve_type=\"increasing\", minimum=0.0, maximum=1.0, scale=0.1)\n",
    "# simulator.update_contribution(factor_i=3, curve_type=\"decreasing\", minimum=0.0, maximum=1.0, scale=0.1)\n",
    "simulator.plot_synthetic_contributions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d605314-c34a-434d-a178-81b6f6b3766d",
   "metadata": {},
   "source": [
    "#### Load Data\n",
    "Assign the processed data and uncertainty datasets to the variables V and U. These steps will be simplified/streamlined in a future version of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee36d66-7066-44d1-ae0b-b8b3e2413bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_input_df, syn_uncertainty_df = simulator.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b90b7-c68c-4d64-af4b-47033406e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler = DataHandler.load_dataframe(input_df=syn_input_df, uncertainty_df=syn_uncertainty_df)\n",
    "data_handler._aggregate_data()\n",
    "V, U = data_handler.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412787cb-62cf-4a86-9a2d-f368030e11db",
   "metadata": {},
   "source": [
    "#### Input/Uncertainty Data Metrics and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d28851-eee3-4682-817e-00ce63e5617b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show the input data metrics, including signal to noise ratio of the data and uncertainty\n",
    "data_handler.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac7440-7f97-4b81-a2ac-6e539f294132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concentration / Uncertainty Scatter plot for specific feature, feature/column specified by index\n",
    "data_handler.plot_data_uncertainty(feature_idx=0, include_menu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c24b313-37ca-412f-b07b-dcd00021773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species Concentration plot comparing features, features/columns specified by index\n",
    "data_handler.plot_feature_data(x_idx=0, y_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dcbac4-80d1-4627-9608-bb7973e36c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species Timeseries, a single or list of features/columns specified by index\n",
    "data_handler.plot_feature_timeseries(feature_selection=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0524672b-b998-4526-b561-cf0cf25b6538",
   "metadata": {},
   "source": [
    "#### Factor Estimator\n",
    "\n",
    "With real datasets, the actual number of factors/sources is typically not known. A best guess and running multiple batchs using different factor counts. To assist this process, a factor search can be done to take a quantitative guess at the optimal number of factors.\n",
    "\n",
    "The factor search will randomly sample a large number of models with different factors, initilaizations, and test masks. The change in the average mean square error (MSE) for each factor count is used as a metric to indicate a potential optimal factor count.\n",
    "\n",
    "The process uses cross-validation where some percent of values in the input dataset, default 10%, are masked out of the calculation of the training MSE. The test MSE is calculated for the masked out values, and these are values are used in estimating the factor count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c4757f-5d8f-414d-92d0-7158a4d56b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and run factor estimator\n",
    "samples = 250\n",
    "min_factors = 2\n",
    "max_factors = 12\n",
    "\n",
    "factor_est = FactorEstimator(V=V, U=U)\n",
    "results = factor_est.run(samples=samples, min_factors=min_factors, max_factors=max_factors)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64336f47-4e42-4d5b-87f2-150cb567d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of the factor search, when using the Simulator we know the actual number of factors and can add it to the plot.\n",
    "factor_est.plot(actual_count=syn_factors)\n",
    "estimated_factors = factor_est.estimated_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f532c5-1e71-4966-8edf-e8f68fa0bd57",
   "metadata": {},
   "source": [
    "#### Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4b336-67a8-4dd1-a758-ed895d933dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_col = \"Date\"                  # the index of the input/uncertainty datasets\n",
    "# factors = syn_factors               # the number of factors\n",
    "factors = 6\n",
    "method = \"ls-nmf\"                   # \"ls-nmf\", \"ws-nmf\"\n",
    "models = 20                         # the number of models to train\n",
    "init_method = \"col_means\"           # default is column means \"col_means\", \"kmeans\", \"cmeans\"\n",
    "init_norm = True                    # if init_method=kmeans or cmeans, normalize the data prior to clustering.\n",
    "seed = 42                           # random seed for initialization\n",
    "max_iterations = 20000              # the maximum number of iterations for fitting a model\n",
    "converge_delta = 0.1                # convergence criteria for the change in loss, Q\n",
    "converge_n = 25                     # convergence criteria for the number of steps where the loss changes by less than converge_delta\n",
    "verbose = True                      # adds more verbosity to the algorithm workflow on execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f561829-6c19-4eeb-b8d3-3f83180b9794",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018eb975-f9dd-4e73-bf1d-8c5b696e6dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Training multiple models, optional parameters are commented out.\n",
    "sa_models = BatchSA(V=V, U=U, factors=factors, models=models, method=method, seed=seed, max_iter=max_iterations,\n",
    "                    init_method=init_method, init_norm=init_norm,\n",
    "                    converge_delta=converge_delta, converge_n=converge_n, \n",
    "                    verbose=True\n",
    "                   )\n",
    "_ = sa_models.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682471c-d3d6-4f5e-9fc1-5bb33f1d8fdd",
   "metadata": {},
   "source": [
    "#### Batch Analysis\n",
    "\n",
    "These methods allow for plotting and reviewing of the overall results of the collection of models produced by the BatchSA training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db50f8b6-a67f-451b-bdb5-9a075632e862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform batch model analysis\n",
    "batch_analysis = BatchAnalysis(batch_sa=sa_models, data_handler=data_handler)\n",
    "# Plot the loss of the models over iterations\n",
    "batch_analysis.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb4e83-0fe9-464d-afcc-bee53123fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss distribution for the batch models\n",
    "batch_analysis.plot_loss_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c65c8d-7826-420d-a4f7-67bc0fcae49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the temporal residuals for each model, the loss by sample, for a specified feature\n",
    "batch_analysis.plot_temporal_residuals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1215ea-feba-4c9f-9377-77097fd16408",
   "metadata": {},
   "source": [
    "### Compare to Synthetic Data\n",
    "\n",
    "Compare the set of batch models to the original synthetic factor data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eafe023-e783-4c17-bf08-7242f375cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator.compare(batch_sa=sa_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857aca0f-44bd-4af7-be54-63812f3647e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator.plot_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f83183-e723-49fe-888c-cfa1e43d7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best mapping of the most optimal model (by loss), plot those mapping results\n",
    "# simulator.plot_comparison(model_i=sa_models.best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfd4755-3533-4cc0-9aa3-4a82a2233691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Simulator instance, saves the instance as a pickle file and saves the synthetic profiles, contributions, data and uncertainty as csv files.\n",
    "# sim_name = \"synthetic\"\n",
    "# sim_output_dir = \"D:/git/esat/notebooks/\"\n",
    "# simulator.save(sim_name=sim_name, output_directory=sim_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316925f4-4e66-4a32-a086-310168b28d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a previously saved Simulator instance\n",
    "# simulator_file = \"D:/git/esat/notebooks/esat_simulator.pkl\"\n",
    "# simulator_2 = Simulator.load(file_path=simulator_file)\n",
    "# simulator_2.factor_compare.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34bd6f8-b78e-42de-8277-912bb142c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selet the highest correlated model\n",
    "best_model = simulator.factor_compare.best_model\n",
    "sa_model = sa_models.results[best_model]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c57f33-ef70-4fae-b47d-04220b773598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Model Analysis module\n",
    "model_analysis = ModelAnalysis(datahandler=data_handler, model=sa_model, selected_model=best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d2bff7-b36a-4837-95a9-1ff2bd90c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Analysis shows the scaled residual histogram, along with metrics and distribution curves. The abs_threshold parameter specifies the condition for the returned values of the function call as those residuals which exceed the absolute value of that threshold.\n",
    "abs_threshold = 3.0\n",
    "threshold_residuals = model_analysis.plot_residual_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d33c4-51b4-4c1d-b01e-7b9667638e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model output statistics for the estimated V, including SE: Standard Error metrics, and 3 normal distribution tests of the residuals (KS Normal is used in PMF5)\n",
    "model_analysis.calculate_statistics()\n",
    "model_analysis.statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d23a88-47f5-4692-ba9b-07e8630d5486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model feature observed vs predicted plot with regression and one-to-one lines. Feature/Column specified by index.\n",
    "model_analysis.plot_estimated_observed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a0280-d275-46d5-973e-48fa55fd51af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model feature timeseries analysis plot showing the observed vs predicted values of the feature, along with the residuals shown below. Feature/column specified by index.\n",
    "model_analysis.plot_estimated_timeseries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da54785-9c7f-4396-b776-f086612ace02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor profile plot showing the factor sum of concentrations by feature (blue bars), the percentage of the feature as the red dot, and in the bottom plot the normalized contributions by date (values are resampled at a daily timestep for timeseries consistency).\n",
    "# Factor specified by index.\n",
    "model_analysis.plot_factor_profile(factor_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e332d6-75b2-4682-ba27-612dfaf26b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model factor fingerprint specifies the feature percentage of each factor.\n",
    "model_analysis.plot_factor_fingerprints(grouped=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8bb85b-b48e-4031-b861-d6f6af5ad090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor G-Space plot shows the normalized contributions of one factor vs another factor. Factor specified by index.\n",
    "model_analysis.plot_g_space(factor_1=2, factor_2=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e299347b-a88c-432b-a68f-270ba15f35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor contribution pie chart shows the percentage of factor contributions for the specified feature, and the corresponding normalized contribution of each factor for that feature (bottom plot). Feature specified by index.\n",
    "model_analysis.plot_factor_contributions(feature_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ecbf01-3cce-4fb4-a6c0-f38037e84d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1f1d08-dfcb-4e52-92e8-78fecd27d6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9320d-7179-48af-9f3e-e291e877aaf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c225f5-0f5c-4588-95eb-db15797dab8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
